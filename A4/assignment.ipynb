{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pywt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\Desktop\\WN Assignment 4\\assignment.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Desktop/WN%20Assignment%204/assignment.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Desktop/WN%20Assignment%204/assignment.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmath\u001b[39;00m \u001b[39mimport\u001b[39;00m sqrt, atan2\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Desktop/WN%20Assignment%204/assignment.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpywt\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Desktop/WN%20Assignment%204/assignment.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Desktop/WN%20Assignment%204/assignment.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mimport\u001b[39;00m figure\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pywt'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt, atan2\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import scipy.signal as signal\n",
    "from hampel import hampel\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import math\n",
    "import difflib\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='set the path of input raw csi data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the input CSI file.\n",
    "def fine_csv(path):\n",
    "    df = pd.read_csv(path, sep=\",\", header=0) \n",
    "    index_names = df[df['mac'] != 'C4:4F:33:7B:83:7E'].index\n",
    "    df.drop(index_names, inplace = True)\n",
    "    df = df.dropna()\n",
    "    # reset the index \n",
    "    df = df.reset_index(drop=True)\n",
    "    print(\"fine_csv completed\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare matrix from the raw data. \n",
    "def prepare_matrix(CSI_DATA):\n",
    "    #df = pd.DataFrame()\n",
    "    csi_matrix=[]\n",
    "    for i in range(0, len(CSI_DATA)):\n",
    "        csi_split =CSI_DATA[i]\n",
    "        csi_split = csi_split = csi_split[1:-1]\n",
    "        csi_raw = [int(x) for x in csi_split.split(\" \") if x != '']\n",
    "        csi_matrix.append(csi_raw)\n",
    "    df = pd.DataFrame(csi_matrix)\n",
    "    print(\"prepare_matrix completed\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_csi(df):\n",
    "    df['rssi'] = pd.to_numeric(df['rssi'])\n",
    "    df['timestamp'] = pd.to_numeric(df['timestamp'])\n",
    "    CSI_DATA = np.array(df.CSI_DATA)\n",
    "    RSSI = np.array(df.rssi)\n",
    "    time = np.array(df.timestamp)\n",
    "    csi_matrix = prepare_matrix(CSI_DATA)\n",
    "\n",
    "    csi_matrix = csi_matrix.reset_index(drop=True)\n",
    "    time = pd.DataFrame(time)\n",
    "    time.columns = ['time']\n",
    "\n",
    "    RSSI = pd.DataFrame(RSSI)\n",
    "    RSSI.columns = ['rssi']\n",
    "    \n",
    "    print(\"prepare_csi completed\")\n",
    "    return csi_matrix, time, RSSI\n",
    "# use name \"time\" varible in the function calling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the \"time\" variable for storing the timestamp values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove Nan values from the csi matrix. \n",
    "def remove_nan(matrix_, time_, rssi_):\n",
    "    temp = pd.concat([matrix_,time_,rssi_], axis=1)\n",
    "    temp = temp.dropna()\n",
    "    temp = temp.reset_index(drop=True)\n",
    "    time = pd.DataFrame(temp.time.values)\n",
    "    rssi = pd.DataFrame(temp.rssi.values)\n",
    "    print(time.shape[0] )\n",
    "    matrix = temp.drop(['time', 'rssi'], axis=1)\n",
    "    print(\"remove_nan completed\")\n",
    "    return  matrix , time, rssi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to find the amplitude and phase of every subscarrier \n",
    "def amp_phase(df):\n",
    "    from math import sqrt, atan2\n",
    "    amp = []\n",
    " \n",
    "    d = np.array(df)\n",
    "    for j in range(len(d)):\n",
    "        imaginary = []\n",
    "        real = []\n",
    "        amplitudes = []\n",
    "      \n",
    "        for i in range(len(d[j])):\n",
    "            if i % 2 == 0:\n",
    "                imaginary.append(d[j][i])\n",
    "            else:\n",
    "                real.append(d[j][i])\n",
    "        for i in range(int(len(d[0]) / 2)):\n",
    "            #write code here. \n",
    "            amplitudes.append(sqrt(imaginary[i] ** 2 + real[i] ** 2))\n",
    "            \n",
    "        amp.append(amplitudes)\n",
    "     \n",
    "    amp = pd.DataFrame(amp)\n",
    "    amp = amp.reset_index(drop=True)\n",
    "\n",
    "    print(\"amp_phase completed\")  \n",
    "     \n",
    "    return amp \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_subcarrier(df):\n",
    "    df = df.iloc[0:,64:]\n",
    "    df.columns = range(df.shape[1])\n",
    "    delete_idxs =  np.asarray([0,1,2,3,4,5,63,64,65,123,124,125,126,127])\n",
    "   \n",
    "    df = df.drop(delete_idxs, axis=1)\n",
    "    df.columns = range(df.shape[1])\n",
    "    print(\"drop_subcarrier completed\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call Here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Norm(amp): \n",
    "    norm_amp=(amp-amp.min())/(amp.max()-amp.min()) # normalize amplitude\n",
    "\n",
    "    norm_amp = pd.DataFrame(norm_amp)\n",
    "    \n",
    "    print(\"Norm completed\") \n",
    "    return norm_amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call; here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code to display the line curve for computed amplitude.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier removal in amplitude\n",
    "def hample_filter(df):\n",
    "        fine_df = df.copy()\n",
    "        length = len(fine_df)\n",
    "        length = int(length/1)\n",
    "        for i in fine_df.columns:#range(len(df_amp.iloc[0]))\n",
    "            temp = hampel(df[i], window_size=length) # find the optimal window_size\n",
    "            fine_df[i]=temp.filtered_data\n",
    "        print(\"hample_filter completed\")\n",
    "        return fine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise(df):\n",
    "    dwt = pd.DataFrame()\n",
    "    \n",
    "    for i in range(len(df.iloc[0])):\n",
    "        signal = df[i]\n",
    "        coeff = pywt.wavedec(signal, wavelet='db4', mode=\"per\")\n",
    "        #coeff\n",
    "        d = np.mean(np.absolute(coeff[-1] - np.mean(coeff[-1], axis=None)), axis=None)\n",
    "        sigma = (1/0.6475) * d\n",
    "        #sigma\n",
    "        uthresh = sigma * np.sqrt(2 * np.log(len(signal)))\n",
    "        #uthresh\n",
    "        coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n",
    "        filter = pywt.waverec(coeff, wavelet='db4', mode='per')\n",
    "        #filter1 = pd.DataFrame(filter)\n",
    "        dwt[i]= filter\n",
    "    dwt = dwt[:-1]\n",
    "    print(\"denoise completed\")\n",
    "    return dwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code to display the line curve for computed amplitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert timestamp into minute and seconds\n",
    "def convert_time(data):\n",
    "    from datetime import datetime\n",
    "    d = data.copy()\n",
    "    #df = d[\"timestamp\"]\n",
    "    time = pd.DataFrame(d)\n",
    "    for i in range(0, len(time)):       \n",
    "        dt_obj = datetime.fromtimestamp(int(time[0][i]))\n",
    "        temp = \"%s.%s\" % (str(dt_obj.minute).zfill(2),str(dt_obj.second).zfill(2))\n",
    "        time.loc[i] = float(temp)\n",
    "        #time.loc[i] = temp\n",
    "    print(\"convert time completed\")\n",
    "    return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    " # apply savgol fiter\n",
    "def savgol(df,train_time ):\n",
    "    rd_data = []\n",
    "    \n",
    "    N_sample = len(df[0])\n",
    "    print(N_sample)\n",
    "    time1 = np.array(train_time)\n",
    "    time1 = np.unique(time1)\n",
    "    print(time1.shape[0])\n",
    "    sam_rate = N_sample+1/time1.shape[0]\n",
    "    print(sam_rate)\n",
    "    for i in range(0, len(df.loc[0])):\n",
    "        rd_ph1 = signal.savgol_filter(df[i], 51,5)\n",
    "        sos = signal.butter(10,20,'low', fs=2*sam_rate, output='sos')\n",
    "        rd_ph1 = signal.sosfiltfilt(sos,rd_ph1)\n",
    "        rd_data.append(rd_ph1)\n",
    "    smooth = pd.DataFrame(rd_data)\n",
    "    smooth = smooth.transpose() \n",
    "    print(\"savgol filter completed\")    \n",
    "    return smooth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code to display the line curve for computed amplitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make input shape as: \n",
    "# First reduce the column dimension to 100 \n",
    "# Then make reshape to 10 X 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining Attention layer. \n",
    "class AttenLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, num_state, **kw):\n",
    "        super(AttenLayer, self).__init__(**kw)\n",
    "        self.num_state = num_state\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight('kernel', shape=[input_shape[-1], self.num_state])\n",
    "        self.bias = self.add_weight('bias', shape=[self.num_state])\n",
    "        self.prob_kernel = self.add_weight('prob_kernel', shape=[self.num_state])\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        atten_state = tf.tanh(tf.tensordot(input_tensor, self.kernel, axes=1) + self.bias)\n",
    "        logits = tf.tensordot(atten_state, self.prob_kernel, axes=1)\n",
    "        prob = tf.nn.softmax(logits)\n",
    "        weighted_feature = tf.reduce_sum(tf.multiply(input_tensor, tf.expand_dims(prob, -1)), axis=1)\n",
    "        return weighted_feature\n",
    "    \n",
    "    # for saving the model\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'num_state': self.num_state,})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining Bi-lstm with Attention Layer model \n",
    "class CSIModelConfig:\n",
    "    def __init__(self, win_len=1000, step=200, thrshd=0.6, downsample=2):\n",
    "        pass\n",
    "    \n",
    "    def build_model(self, n_unit_lstm=200, n_unit_atten=400):\n",
    "        \"\"\"\n",
    "        Returns the Tensorflow Model which uses AttenLayer\n",
    "        \"\"\"\n",
    "        if self._downsample > 1:\n",
    "            length = len(np.ones((self._win_len,))[::self._downsample])\n",
    "            x_in = tf.keras.Input(shape=(length, 10))\n",
    "        else:\n",
    "            x_in = tf.keras.Input(shape=(self._win_len, 10))\n",
    "        x_tensor = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=n_unit_lstm, return_sequences=True))(x_in)\n",
    "        x_tensor = AttenLayer(n_unit_atten)(x_tensor)\n",
    "        pred = tf.keras.layers.Dense(len(self._labels), activation='softmax')(x_tensor)\n",
    "        model = tf.keras.Model(inputs=x_in, outputs=pred)\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def load_model(hdf5path):\n",
    "        \"\"\"\n",
    "        Returns the Tensorflow Model for AttenLayer\n",
    "        Args:\n",
    "            hdf5path: str, the model file path\n",
    "        \"\"\"\n",
    "        model = tf.keras.models.load_model(hdf5path, custom_objects={'AttenLayer':AttenLayer})\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading pretrained model\n",
    "model = tf.keras.models.load_model('Set the trained model path',custom_objects={'AttenLayer':AttenLayer})\n",
    "# input shape reuired by the model is 10 X 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict here\n",
    "y_pred= \"write code here\"\n",
    "t1= np.argmax(y_pred, axis=1)\n",
    "t1 = pd.DataFrame(t1)\n",
    "t1.columns=['headlabel']\n",
    "t1.headlabel.replace((0, 1,2, 3,4,5,6),('Forward', 'Looking Up', 'Nodding', 'Looking Down', 'Shaking','Looking Left', 'Looking Right'), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engagement score calculations\n",
    "def calc_score(seq):\n",
    "        score=0\n",
    "        for i in seq:\n",
    "            if(i==1 or i==2 or i==3):\n",
    "                score+=1\n",
    "            elif(i==6 or i==7 or i==5):\n",
    "                score-=1\n",
    "            elif(i==4):\n",
    "                score+=0.8\n",
    "            elif(i==8):\n",
    "                score-=1\n",
    "            # else:\n",
    "            #     score+=0.5\n",
    "        return score/len(seq)\n",
    "def engagement_score(time, t1):\n",
    "    headlabel_rank={'Forward':1, 'Nodding':2, 'Shaking':3, 'Looking Down':4, 'Looking Up':5, 'Looking Left':6, 'Looking Right':7, 'Unknown Gesture':8}\n",
    "    time.columns= ['timestamp']\n",
    "    end_time=time['timestamp'][time.shape[0]-1]\n",
    "    start_time=time['timestamp'][0]\n",
    "    total_time=end_time-start_time\n",
    "    windows=total_time/10\n",
    "    windows=math.floor(windows)\n",
    "\n",
    "    window_size=(time.shape[0]+1)/windows\n",
    "    window_size=math.floor(window_size)\n",
    "    headlabels=[]\n",
    "\n",
    "    for label in t1['headlabel']:\n",
    "        headlabels.append(headlabel_rank[label])\n",
    "    Windows=[]\n",
    "    index=0\n",
    "    for i in range(windows):\n",
    "        Window=[]\n",
    "        for j in range(window_size):\n",
    "            try:\n",
    "                Window.append(headlabels[index])\n",
    "                index=index+1\n",
    "            except:\n",
    "                print(\"\")\n",
    "        Windows.append(Window)\n",
    "    Windows_index=collections.deque()\n",
    "    for i in range(len(Windows)):\n",
    "        Windows_index.append(i)\n",
    "\n",
    "    Clusters=[]\n",
    "\n",
    "    while(len(Windows_index)>0):\n",
    "\n",
    "        Cluster=[]\n",
    "        first_index=Windows_index.popleft()\n",
    "        Window=Windows[first_index]\n",
    "        Cluster.append((first_index,Window))\n",
    "        indexes=[]\n",
    "        for index in Windows_index:\n",
    "            sm=difflib.SequenceMatcher(None,Window,Windows[index])\n",
    "            if(sm.ratio()>0.70): # similarity score\n",
    "                indexes.append(index)\n",
    "                Cluster.append((index,Windows[index]))\n",
    "        for index in indexes:\n",
    "            Windows_index.remove(index)\n",
    "        Clusters.append(Cluster)\n",
    "    scores=[0]*windows\n",
    "    for cluster in Clusters:\n",
    "        temp_score=[]\n",
    "        for j in cluster:\n",
    "            seq_score=calc_score(j[1])\n",
    "            temp_score.append(seq_score)\n",
    "        #sequence=cluster[0][1]\n",
    "        #score=calc_score(sequence)\n",
    "        score=max(temp_score)\n",
    "        for seq in cluster:\n",
    "            index=seq[0]\n",
    "            scores[index]=score\n",
    "    thresholds=[0.55]\n",
    "\n",
    "    model_eng=[]\n",
    "    window=[]\n",
    "    for threshold in thresholds:\n",
    "        win=0\n",
    "        engaged=[]\n",
    "        print(\"threshold: \",threshold)\n",
    "        for i in scores:\n",
    "            if(i>=threshold): # threshold for enumerating engage or disengage. \n",
    "                engaged.append(1)\n",
    "                model_eng.append(1)\n",
    "                win=win+1\n",
    "                window.append(win)\n",
    "            else:\n",
    "                engaged.append(0)\n",
    "                model_eng.append(0)\n",
    "                win=win+1\n",
    "                window.append(win)\n",
    "    print(sum(engaged)/len(engaged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call Here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
